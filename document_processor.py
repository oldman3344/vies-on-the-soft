#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æ¡£å¤„ç†æ¨¡å—
ç”¨äºå¤„ç†Excelæ•°æ®æå–å’ŒWordæ–‡æ¡£è¡¨æ ¼å¡«å……
"""

import pandas as pd
import openpyxl
from docx import Document
from docx.shared import Inches, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.parser import OxmlElement
from docx.oxml.ns import qn
import os
import logging
from typing import List, Dict, Any, Optional, Tuple

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DocumentProcessor:
    """æ–‡æ¡£å¤„ç†å™¨ç±»"""
    
    def __init__(self):
        self.excel_data = None
        self.word_doc = None
        self._template_cache = {}  # æ¨¡æ¿å†…å®¹ç¼“å­˜
        self._last_template_path = None  # ä¸Šæ¬¡ä½¿ç”¨çš„æ¨¡æ¿è·¯å¾„
    
    def set_table_borders(self, table):
        """
        ä¸ºè¡¨æ ¼è®¾ç½®å®çº¿è¾¹æ¡†
        """
        try:
            from docx.oxml import parse_xml
            
            # è·å–è¡¨æ ¼çš„XMLå…ƒç´ 
            tbl = table._tbl
            
            # åˆ›å»ºè¡¨æ ¼è¾¹æ¡†å±æ€§
            tblPr = tbl.tblPr
            if tblPr is None:
                tblPr = parse_xml('<w:tblPr xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main"/>')
                tbl.insert(0, tblPr)
            
            # åˆ›å»ºè¡¨æ ¼è¾¹æ¡†XML
            borders_xml = '''
            <w:tblBorders xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">
                <w:top w:val="single" w:sz="4" w:space="0" w:color="000000"/>
                <w:left w:val="single" w:sz="4" w:space="0" w:color="000000"/>
                <w:bottom w:val="single" w:sz="4" w:space="0" w:color="000000"/>
                <w:right w:val="single" w:sz="4" w:space="0" w:color="000000"/>
                <w:insideH w:val="single" w:sz="4" w:space="0" w:color="000000"/>
                <w:insideV w:val="single" w:sz="4" w:space="0" w:color="000000"/>
            </w:tblBorders>
            '''
            
            # è§£æè¾¹æ¡†XML
            tblBorders = parse_xml(borders_xml)
            
            # ç§»é™¤ç°æœ‰çš„è¾¹æ¡†è®¾ç½®ï¼ˆå¦‚æœæœ‰ï¼‰
            existing_borders = tblPr.find(qn('w:tblBorders'))
            if existing_borders is not None:
                tblPr.remove(existing_borders)
            
            # æ·»åŠ æ–°çš„è¾¹æ¡†è®¾ç½®
            tblPr.append(tblBorders)
            
        except Exception as e:
            logger.warning(f"è®¾ç½®è¡¨æ ¼è¾¹æ¡†æ—¶å‡ºé”™: {e}")
            # å¦‚æœè®¾ç½®è¾¹æ¡†å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œï¼Œä¸å½±å“ä¸»è¦åŠŸèƒ½
    
    def set_row_dashed_borders(self, row):
        """
        è®¾ç½®è¡¨æ ¼è¡Œçš„è¾¹æ¡†ä¸ºè™šçº¿
        
        Args:
            row: Wordè¡¨æ ¼è¡Œå¯¹è±¡
        """
        try:
            for cell in row.cells:
                # è·å–å•å…ƒæ ¼å±æ€§
                tc_pr = cell._tc.tcPr
                if tc_pr is None:
                    tc_pr = OxmlElement('w:tcPr')
                    cell._tc.insert(0, tc_pr)
                
                # æ„å»ºè™šçº¿è¾¹æ¡†XML
                borders_xml = '''
                <w:tcBorders xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main">
                    <w:top w:val="dashed" w:sz="4" w:space="0" w:color="000000"/>
                    <w:left w:val="dashed" w:sz="4" w:space="0" w:color="000000"/>
                    <w:bottom w:val="dashed" w:sz="4" w:space="0" w:color="000000"/>
                    <w:right w:val="dashed" w:sz="4" w:space="0" w:color="000000"/>
                </w:tcBorders>
                '''
                
                # è§£æXMLå¹¶æ·»åŠ åˆ°å•å…ƒæ ¼å±æ€§ä¸­
                from docx.oxml import parse_xml
                borders_element = parse_xml(borders_xml)
                
                # ç§»é™¤ç°æœ‰çš„è¾¹æ¡†è®¾ç½®
                existing_borders = tc_pr.find(qn('w:tcBorders'))
                if existing_borders is not None:
                    tc_pr.remove(existing_borders)
                
                # æ·»åŠ æ–°çš„è¾¹æ¡†è®¾ç½®
                tc_pr.append(borders_element)
            
            logger.info("è¡Œè¾¹æ¡†å·²è®¾ç½®ä¸ºè™šçº¿")
            
        except Exception as e:
            logger.warning(f"è®¾ç½®è¡Œè™šçº¿è¾¹æ¡†æ—¶å‡ºé”™: {e}")

    def add_material_info_row(self, table, template_content=None):
        """
        åœ¨è¡¨æ ¼æœ«å°¾æ·»åŠ ç”³æŠ¥ææ–™è¯´æ˜è¡Œ
        
        Args:
            table: Wordè¡¨æ ¼å¯¹è±¡
            template_content: æ¨¡æ¿ä¸­çš„ç”³æŠ¥ææ–™è¯´æ˜å†…å®¹ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å†…å®¹
        """
        try:
            # æ·»åŠ æ–°è¡Œ
            new_row = table.add_row()
            
            # åˆå¹¶æ‰€æœ‰å•å…ƒæ ¼
            if len(new_row.cells) > 1:
                # åˆå¹¶ç¬¬ä¸€ä¸ªå•å…ƒæ ¼å’Œå…¶ä»–æ‰€æœ‰å•å…ƒæ ¼
                merged_cell = new_row.cells[0]
                for i in range(1, len(new_row.cells)):
                    merged_cell.merge(new_row.cells[i])
            
            # è®¾ç½®æ–‡æœ¬å†…å®¹ - åˆ†ä¸ºä¸¤éƒ¨åˆ†è®¾ç½®ä¸åŒæ ·å¼
            cell = new_row.cells[0]
            
            # æ¸…ç©ºé»˜è®¤æ–‡æœ¬
            cell.text = ""
            
            # è·å–æ®µè½
            paragraph = cell.paragraphs[0]
            paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
            
            # ç¬¬ä¸€éƒ¨åˆ†ï¼šç”³æŠ¥éœ€æä¾›ä»¥ä¸‹ææ–™ï¼š - åŠ å¤§åŠ ç²—é»‘è‰²
            title_run = paragraph.add_run("ç”³æŠ¥éœ€æä¾›ä»¥ä¸‹ææ–™ï¼š")
            title_run.font.size = Pt(12)  # åŠ å¤§å­—ä½“
            title_run.font.name = 'å®‹ä½“'
            title_run.font.bold = True  # åŠ ç²—
            title_run.font.color.rgb = None  # é»‘è‰²ï¼ˆé»˜è®¤ï¼‰
            
            # ç¬¬äºŒéƒ¨åˆ†ï¼šæ‹¬å·å†…å®¹ - çº¢è‰²åŠ ç²—ï¼Œä¸æ ‡é¢˜å­—ä½“å¤§å°ä¸€è‡´
            # å¦‚æœæä¾›äº†æ¨¡æ¿å†…å®¹ï¼Œä½¿ç”¨æ¨¡æ¿å†…å®¹ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤å†…å®¹
            if template_content:
                content_text = template_content
            else:
                # é»˜è®¤å†…å®¹ï¼ˆä¸å›¾ç‰‡ä¸­ä¸€è‡´ï¼‰
                content_text = "ï¼ˆä¸‹è½½æ—¶é—´ï¼š10æœˆ03å·å¼€å§‹ï¼Œè¯·åœ¨10æœˆ05æ—¥å‰æä¾›ï¼Œå¦‚ä¸åŠæ—¶ç”³æŠ¥ï¼Œå¹³å°é€ æˆçš„åæœsmkä¸æ‰¿ä»»ä½•è´£ä»»ï¼‰"
            
            content_run = paragraph.add_run(content_text)
            content_run.font.size = Pt(12)  # ä¸æ ‡é¢˜å­—ä½“å¤§å°ä¸€è‡´
            content_run.font.name = 'å®‹ä½“'
            content_run.font.bold = True  # åŠ ç²—
            
            # è®¾ç½®çº¢è‰²
            from docx.shared import RGBColor
            content_run.font.color.rgb = RGBColor(255, 0, 0)  # çº¢è‰²
            
            # è®¾ç½®è™šçº¿è¾¹æ¡†
            self.set_row_dashed_borders(new_row)
            
            logger.info("å·²æ·»åŠ ç”³æŠ¥ææ–™è¯´æ˜è¡Œ")
            
        except Exception as e:
            logger.warning(f"æ·»åŠ ç”³æŠ¥ææ–™è¯´æ˜è¡Œæ—¶å‡ºé”™: {e}")
    
    def extract_material_info_from_template(self, word_path: str) -> Optional[str]:
        """
        ä»Wordæ¨¡æ¿ä¸­æå–ç”³æŠ¥ææ–™è¯´æ˜çš„åŸå§‹å†…å®¹
        
        Args:
            word_path: Wordæ¨¡æ¿æ–‡ä»¶è·¯å¾„
            
        Returns:
            ç”³æŠ¥ææ–™è¯´æ˜å†…å®¹ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
        """
        try:
            logger.info(f"æ­£åœ¨ä»æ¨¡æ¿æ–‡ä»¶æå–ç”³æŠ¥ææ–™è¯´æ˜: {word_path}")
            
            # æ£€æŸ¥æ¨¡æ¿è·¯å¾„æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼Œå¦‚æœå˜åŒ–åˆ™æ¸…é™¤ç¼“å­˜
            if self._last_template_path != word_path:
                logger.info(f"æ£€æµ‹åˆ°æ¨¡æ¿è·¯å¾„å˜åŒ–: {self._last_template_path} -> {word_path}")
                logger.info(f"æ¸…é™¤ç¼“å­˜å‰ï¼Œç¼“å­˜é¡¹æ•°: {len(self._template_cache)}")
                self._template_cache.clear()
                logger.info("âœ… å› è·¯å¾„å˜åŒ–å·²æ¸…é™¤ç¼“å­˜")
                self._last_template_path = word_path
            
            # æ£€æŸ¥ç¼“å­˜
            if word_path in self._template_cache:
                cached_content = self._template_cache[word_path]
                logger.info("ğŸ“‹ ä»ç¼“å­˜ä¸­è·å–æ¨¡æ¿å†…å®¹")
                logger.info(f"ğŸ“‹ ç¼“å­˜å†…å®¹é¢„è§ˆ: {cached_content[:50] if cached_content else 'None'}...")
                return cached_content
            
            # ç¡®ä¿æ–‡ä»¶å­˜åœ¨
            if not os.path.exists(word_path):
                logger.error(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {word_path}")
                return None
            
            # åˆ›å»ºæ–°çš„Documentå¯¹è±¡ï¼Œç¡®ä¿è¯»å–æœ€æ–°çš„æ–‡ä»¶å†…å®¹
            doc = Document(word_path)
            
            # éå†æ‰€æœ‰è¡¨æ ¼ï¼ŒæŸ¥æ‰¾åŒ…å«"ç”³æŠ¥éœ€æä¾›ä»¥ä¸‹ææ–™"çš„è¡Œ
            for table_idx, table in enumerate(doc.tables):
                for row_idx, row in enumerate(table.rows):
                    for cell_idx, cell in enumerate(row.cells):
                        cell_text = cell.text.strip()
                        if "ç”³æŠ¥éœ€æä¾›ä»¥ä¸‹ææ–™" in cell_text:
                            logger.info(f"åœ¨è¡¨æ ¼{table_idx}çš„ç¬¬{row_idx}è¡Œç¬¬{cell_idx}åˆ—æ‰¾åˆ°ç”³æŠ¥ææ–™è¯´æ˜")
                            # æ‰¾åˆ°äº†ç”³æŠ¥ææ–™è¯´æ˜è¡Œï¼Œæå–æ‹¬å·å†…çš„å†…å®¹
                            if "ï¼ˆ" in cell_text and "ï¼‰" in cell_text:
                                start_idx = cell_text.find("ï¼ˆ")
                                end_idx = cell_text.find("ï¼‰") + 1
                                if start_idx != -1 and end_idx != -1:
                                    template_content = cell_text[start_idx:end_idx]
                                    logger.info(f"ä»æ¨¡æ¿ä¸­æå–åˆ°ç”³æŠ¥ææ–™è¯´æ˜: {template_content}")
                                    # å­˜å…¥ç¼“å­˜
                                    self._template_cache[word_path] = template_content
                                    # æ˜¾å¼æ¸…ç†æ–‡æ¡£å¯¹è±¡
                                    doc = None
                                    return template_content
            
            logger.info("æ¨¡æ¿ä¸­æœªæ‰¾åˆ°ç”³æŠ¥ææ–™è¯´æ˜ï¼Œå°†ä½¿ç”¨é»˜è®¤å†…å®¹")
            # å­˜å…¥ç¼“å­˜ï¼ˆNoneå€¼ä¹Ÿè¦ç¼“å­˜ï¼Œé¿å…é‡å¤è¯»å–ï¼‰
            self._template_cache[word_path] = None
            # æ˜¾å¼æ¸…ç†æ–‡æ¡£å¯¹è±¡
            doc = None
            return None
            
        except Exception as e:
            logger.warning(f"ä»æ¨¡æ¿æå–ç”³æŠ¥ææ–™è¯´æ˜æ—¶å‡ºé”™: {e}")
            return None
    
    def clear_template_cache(self):
        """
        æ¸…é™¤æ¨¡æ¿ç¼“å­˜
        å½“ç”¨æˆ·é€‰æ‹©æ–°çš„æ¨¡æ¿æ–‡ä»¶æ—¶åº”è¯¥è°ƒç”¨æ­¤æ–¹æ³•
        """
        cache_count = len(self._template_cache)
        logger.info(f"æ¸…é™¤æ¨¡æ¿ç¼“å­˜ï¼Œå½“å‰ç¼“å­˜é¡¹æ•°: {cache_count}")
        if cache_count > 0:
            logger.info(f"ç¼“å­˜çš„æ¨¡æ¿è·¯å¾„: {list(self._template_cache.keys())}")
        self._template_cache.clear()
        self._last_template_path = None
        logger.info("âœ… æ¨¡æ¿ç¼“å­˜å·²æ¸…é™¤")
        
    def extract_excel_data(self, excel_path: str, sheet_name: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        ä»Excelæ–‡ä»¶ä¸­æå–æ•°æ® - è‡ªåŠ¨æ£€æµ‹æ‰€æœ‰æœ‰æ•ˆæ•°æ®è¡Œ
        
        Args:
            excel_path: Excelæ–‡ä»¶è·¯å¾„
            sheet_name: å·¥ä½œè¡¨åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
            
        Returns:
            æå–çš„æ•°æ®åˆ—è¡¨
        """
        try:
            # è¯»å–Excelæ–‡ä»¶
            if sheet_name:
                df = pd.read_excel(excel_path, sheet_name=sheet_name)
            else:
                df = pd.read_excel(excel_path)
            
            logger.info(f"æˆåŠŸè¯»å–Excelæ–‡ä»¶: {excel_path}")
            logger.info(f"åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
            logger.info(f"åˆ—å: {list(df.columns)}")
            
            # ç¬¬ä¸€æ­¥ï¼šç§»é™¤å®Œå…¨ç©ºç™½çš„è¡Œ
            df = df.dropna(how='all')
            logger.info(f"ç§»é™¤ç©ºè¡Œåæ•°æ®å½¢çŠ¶: {df.shape}")
            
            # ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½è¿‡æ»¤æœ‰æ•ˆæ•°æ®è¡Œ
            data_list = []
            for idx, row in df.iterrows():
                row_dict = row.to_dict()
                
                # æ£€æŸ¥è¡Œæ˜¯å¦åŒ…å«æœ‰æ•ˆæ•°æ®
                has_valid_data = False
                non_empty_values = 0
                
                for key, value in row_dict.items():
                    if not pd.isna(value) and str(value).strip():
                        non_empty_values += 1
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«VATç›¸å…³ä¿¡æ¯æˆ–å…¶ä»–æœ‰æ•ˆä¸šåŠ¡æ•°æ®
                        value_str = str(value).lower().strip()
                        if ('vat' in value_str or 
                            len(value_str) > 2 or  # æœ‰æ„ä¹‰çš„æ–‡æœ¬
                            value_str.replace('.', '').replace(',', '').replace('-', '').isdigit()):  # æ•°å­—æ•°æ®
                            has_valid_data = True
                
                # å¦‚æœè¡Œæœ‰è¶³å¤Ÿçš„éç©ºæ•°æ®ä¸”åŒ…å«æœ‰æ•ˆä¿¡æ¯ï¼Œåˆ™åŒ…å«æ­¤è¡Œ
                if has_valid_data and non_empty_values >= 2:  # è‡³å°‘2ä¸ªéç©ºå­—æ®µ
                    # æ¸…ç†æ•°æ®ï¼Œå°†NaNæ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²
                    cleaned_row = {}
                    for key, value in row_dict.items():
                        if pd.isna(value):
                            cleaned_row[key] = ""
                        else:
                            cleaned_row[key] = str(value).strip()
                    
                    data_list.append(cleaned_row)
            
            self.excel_data = data_list
            logger.info(f"âœ… è‡ªåŠ¨æ£€æµ‹å¹¶æå–åˆ° {len(data_list)} è¡Œæœ‰æ•ˆæ•°æ®")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ•°æ®ï¼Œå°è¯•æ›´å®½æ¾çš„æ¡ä»¶
            if not data_list:
                logger.warning("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®ï¼Œå°è¯•æ›´å®½æ¾çš„ç­›é€‰æ¡ä»¶...")
                for idx, row in df.iterrows():
                    row_dict = row.to_dict()
                    non_empty_count = sum(1 for v in row_dict.values() 
                                        if not pd.isna(v) and str(v).strip())
                    
                    if non_empty_count >= 1:  # è‡³å°‘1ä¸ªéç©ºå­—æ®µ
                        cleaned_row = {}
                        for key, value in row_dict.items():
                            if pd.isna(value):
                                cleaned_row[key] = ""
                            else:
                                cleaned_row[key] = str(value).strip()
                        data_list.append(cleaned_row)
                
                self.excel_data = data_list
                logger.info(f"ğŸ“‹ ä½¿ç”¨å®½æ¾æ¡ä»¶æå–åˆ° {len(data_list)} è¡Œæ•°æ®")
            
            return data_list
            
        except Exception as e:
            logger.error(f"æå–Excelæ•°æ®æ—¶å‡ºé”™: {e}")
            raise
    
    def get_excel_sheets(self, excel_path: str) -> List[str]:
        """
        è·å–Excelæ–‡ä»¶ä¸­æ‰€æœ‰å·¥ä½œè¡¨çš„åç§°
        
        Args:
            excel_path: Excelæ–‡ä»¶è·¯å¾„
            
        Returns:
            å·¥ä½œè¡¨åç§°åˆ—è¡¨
        """
        try:
            excel_file = pd.ExcelFile(excel_path)
            return excel_file.sheet_names
        except Exception as e:
            logger.error(f"è·å–Excelå·¥ä½œè¡¨åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def get_excel_columns(self, excel_path: str, sheet_name: Optional[str] = None) -> List[str]:
        """
        è·å–Excelæ–‡ä»¶çš„åˆ—å
        
        Args:
            excel_path: Excelæ–‡ä»¶è·¯å¾„
            sheet_name: å·¥ä½œè¡¨åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
            
        Returns:
            åˆ—ååˆ—è¡¨
        """
        try:
            if sheet_name:
                df = pd.read_excel(excel_path, sheet_name=sheet_name, nrows=0)
            else:
                df = pd.read_excel(excel_path, nrows=0)
            return list(df.columns)
        except Exception as e:
            logger.error(f"è·å–Excelåˆ—åå¤±è´¥: {e}")
            return []
    
    def analyze_word_document(self, word_path: str) -> Dict[str, Any]:
        """
        åˆ†æWordæ–‡æ¡£ç»“æ„
        
        Args:
            word_path: Wordæ–‡æ¡£è·¯å¾„
            
        Returns:
            æ–‡æ¡£åˆ†æç»“æœ
        """
        try:
            doc = Document(word_path)
            
            analysis = {
                'paragraphs_count': len(doc.paragraphs),
                'tables_count': len(doc.tables),
                'tables_info': []
            }
            
            # åˆ†æè¡¨æ ¼
            for i, table in enumerate(doc.tables):
                table_info = {
                    'table_index': i,
                    'rows': len(table.rows),
                    'columns': len(table.columns),
                    'content': []
                }
                
                # è·å–è¡¨æ ¼å†…å®¹
                for row_idx, row in enumerate(table.rows):
                    row_content = []
                    for cell in row.cells:
                        row_content.append(cell.text.strip())
                    table_info['content'].append(row_content)
                
                analysis['tables_info'].append(table_info)
            
            logger.info(f"Wordæ–‡æ¡£åˆ†æå®Œæˆ: {analysis}")
            return analysis
            
        except Exception as e:
            logger.error(f"åˆ†æWordæ–‡æ¡£æ—¶å‡ºé”™: {e}")
            raise
    
    def fill_word_table(self, word_path: str, excel_data: List[Dict[str, Any]], 
                       output_path: str, table_index: int = 0,
                       column_mapping: Optional[Dict[str, str]] = None) -> str:
        """
        å°†Excelæ•°æ®å¡«å……åˆ°Wordè¡¨æ ¼ä¸­
        
        Args:
            word_path: Wordæ¨¡æ¿æ–‡ä»¶è·¯å¾„
            excel_data: Excelæ•°æ®
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            table_index: è¦å¡«å……çš„è¡¨æ ¼ç´¢å¼•
            column_mapping: åˆ—æ˜ å°„å…³ç³» {excel_column: word_table_column}
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            # é¦–å…ˆä»æ¨¡æ¿ä¸­æå–ç”³æŠ¥ææ–™è¯´æ˜å†…å®¹
            template_material_info = self.extract_material_info_from_template(word_path)
            
            # æ‰“å¼€Wordæ–‡æ¡£
            doc = Document(word_path)
            
            if table_index >= len(doc.tables):
                raise ValueError(f"è¡¨æ ¼ç´¢å¼• {table_index} è¶…å‡ºèŒƒå›´ï¼Œæ–‡æ¡£åªæœ‰ {len(doc.tables)} ä¸ªè¡¨æ ¼")

            table = doc.tables[table_index]
            
            # å¦‚æœæ²¡æœ‰æä¾›åˆ—æ˜ å°„ï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„
            if column_mapping is None:
                # æ ¹æ®Excelæ•°æ®çš„åˆ—ååˆ›å»ºé»˜è®¤æ˜ å°„
                if excel_data:
                    excel_columns = list(excel_data[0].keys())
                    column_mapping = {}
                    # è·å–Wordè¡¨æ ¼è¡¨å¤´
                    word_headers = [cell.text.strip() for cell in table.rows[0].cells]
                    for i, excel_col in enumerate(excel_columns):
                        if i < len(word_headers):
                            # å°†Excelåˆ—åæ˜ å°„åˆ°Wordè¡¨å¤´
                            column_mapping[word_headers[i]] = excel_col
            
            logger.info(f"ä½¿ç”¨åˆ—æ˜ å°„: {column_mapping}")
            
            # ç¡®ä¿è¡¨æ ¼æœ‰è¶³å¤Ÿçš„è¡Œ
            current_rows = len(table.rows)
            needed_rows = len(excel_data) + 1  # +1 for header
            
            # æ·»åŠ è¡Œå¦‚æœéœ€è¦
            while len(table.rows) < needed_rows:
                table.add_row()
            
            # åˆ é™¤æ‰€æœ‰éè¡¨å¤´è¡Œï¼ˆé¿å…åˆå¹¶å•å…ƒæ ¼é—®é¢˜ï¼‰
            rows_to_remove = []
            for row_idx in range(len(table.rows) - 1, 0, -1):  # ä»åå¾€å‰åˆ é™¤
                rows_to_remove.append(row_idx)
            
            for row_idx in rows_to_remove:
                table._tbl.remove(table.rows[row_idx]._tr)
            
            # å¡«å……æ•°æ®
            for row_idx, data_row in enumerate(excel_data):
                # ä»ç¬¬äºŒè¡Œå¼€å§‹å¡«å……ï¼ˆç¬¬ä¸€è¡Œé€šå¸¸æ˜¯è¡¨å¤´ï¼‰
                word_row_idx = row_idx + 1
                
                if word_row_idx >= len(table.rows):
                    table.add_row()
                
                word_row = table.rows[word_row_idx]
                
                # å¡«å……æ¯ä¸€åˆ—
                if column_mapping:
                    # è·å–Wordè¡¨æ ¼è¡¨å¤´
                    word_headers = [cell.text.strip() for cell in table.rows[0].cells]
                    
                    # éå†Wordè¡¨æ ¼çš„æ¯ä¸€åˆ—
                    for word_col_idx, word_header in enumerate(word_headers):
                        if word_header in column_mapping:
                            # è·å–å¯¹åº”çš„Excelåˆ—å
                            excel_col_name = column_mapping[word_header]
                            if excel_col_name in data_row:
                                cell = word_row.cells[word_col_idx]
                                cell.text = str(data_row[excel_col_name])
                                
                                # è®¾ç½®å•å…ƒæ ¼å¯¹é½æ–¹å¼
                                for paragraph in cell.paragraphs:
                                    paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            # è®¾ç½®è¡¨æ ¼è¾¹æ¡†ä¸ºå®çº¿
            self.set_table_borders(table)
            
            # æ·»åŠ ç”³æŠ¥ææ–™è¯´æ˜è¡Œï¼Œä½¿ç”¨ä»æ¨¡æ¿æå–çš„å†…å®¹
            self.add_material_info_row(table, template_material_info)
            
            # ä¿å­˜æ–‡æ¡£
            doc.save(output_path)
            logger.info(f"Wordæ–‡æ¡£å·²ä¿å­˜åˆ°: {output_path}")
            
            return output_path
            
        except Exception as e:
            logger.error(f"å¡«å……Wordè¡¨æ ¼æ—¶å‡ºé”™: {e}")
            raise
    
    def process_documents(self, excel_path: str, word_template_path: str, 
                         output_path: str, sheet_name: Optional[str] = None,
                         column_mapping: Optional[Dict[str, str]] = None,
                         processing_mode: str = "single") -> Dict[str, Any]:
        """
        å®Œæ•´çš„æ–‡æ¡£å¤„ç†æµç¨‹ - æ”¯æŒå•ä¸ªå’Œå¤šä¸ªå¤„ç†æ¨¡å¼
        
        Args:
            excel_path: Excelæ–‡ä»¶è·¯å¾„
            word_template_path: Wordæ¨¡æ¿è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            sheet_name: Excelå·¥ä½œè¡¨åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
            column_mapping: åˆ—æ˜ å°„
            processing_mode: å¤„ç†æ¨¡å¼ï¼Œ"single"æŒ‰å…¬å¸åç§°åˆ†ç»„ï¼Œ"multiple"æŒ‰ç¾¤åç§°åˆ†ç»„
            
        Returns:
            åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸
        """
        try:
            # 1. æå–Excelæ•°æ®ï¼ˆè‡ªåŠ¨æ£€æµ‹æ‰€æœ‰æœ‰æ•ˆè¡Œï¼‰
            excel_data = self.extract_excel_data(excel_path, sheet_name)
            
            if not excel_data:
                return {
                    'success': False,
                    'error': 'æœªæ‰¾åˆ°æœ‰æ•ˆçš„Excelæ•°æ®',
                    'output_path': None,
                    'rows_filled': 0,
                    'total_rows_detected': 0
                }
            
            logger.info(f"ğŸ¯ å°†å¤„ç†æ‰€æœ‰æ£€æµ‹åˆ°çš„ {len(excel_data)} è¡Œæœ‰æ•ˆæ•°æ®")
            logger.info(f"ğŸ“‹ å¤„ç†æ¨¡å¼: {processing_mode}")
            
            # 2. åˆ†æWordæ–‡æ¡£
            word_analysis = self.analyze_word_document(word_template_path)
            
            # 3. æ ¹æ®å¤„ç†æ¨¡å¼è¿›è¡Œåˆ†ç»„å¤„ç†
            if processing_mode == "single":
                # æŒ‰å…¬å¸åç§°åˆ†ç»„ï¼Œæ¯ä¸ªå…¬å¸ç”Ÿæˆä¸€ä¸ªæ–‡æ¡£
                return self._process_by_company(excel_data, word_template_path, output_path, column_mapping)
            elif processing_mode == "multiple":
                # æŒ‰ç¾¤åç§°åˆ†ç»„ï¼ŒåŒä¸€ç¾¤ç”Ÿæˆä¸€ä¸ªæ–‡æ¡£
                return self._process_by_group(excel_data, word_template_path, output_path, column_mapping)
            else:
                # é»˜è®¤å¤„ç†ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                return self._process_single_document(excel_data, word_template_path, output_path, column_mapping)
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return {
                'success': False,
                'error': str(e),
                'output_path': None,
                'rows_filled': 0,
                'total_rows_detected': 0
            }
    
    def _process_single_document(self, excel_data: List[Dict[str, Any]], 
                               word_template_path: str, output_path: str,
                               column_mapping: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªæ–‡æ¡£ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        """
        try:
            # ç”Ÿæˆè¾“å‡ºè·¯å¾„ï¼ˆå¦‚æœæœªæä¾›ï¼‰
            if not output_path:
                base_name = os.path.splitext(os.path.basename(word_template_path))[0]
                output_dir = os.path.dirname(word_template_path)
                output_path = os.path.join(output_dir, f"{base_name}_å·²å¡«å…….docx")
            
            # å¡«å……Wordè¡¨æ ¼
            result_path = self.fill_word_table(
                word_template_path, 
                excel_data, 
                output_path, 
                0, 
                column_mapping
            )
            
            logger.info(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶: {result_path}")
            return {
                'success': True,
                'error': None,
                'output_path': result_path,
                'rows_filled': len(excel_data),
                'total_rows_detected': len(excel_data)
            }
        except Exception as e:
            logger.error(f"å•æ–‡æ¡£å¤„ç†å‡ºé”™: {e}")
            return {
                'success': False,
                'error': str(e),
                'output_path': None,
                'rows_filled': 0,
                'total_rows_detected': len(excel_data)
            }
    
    def _process_by_company(self, excel_data: List[Dict[str, Any]], 
                          word_template_path: str, output_path: str,
                          column_mapping: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
        """
        æŒ‰å…¬å¸åç§°åˆ†ç»„å¤„ç†ï¼Œæ¯ä¸ªå…¬å¸ç”Ÿæˆä¸€ä¸ªæ–‡æ¡£
        """
        try:
            # æŒ‰å…¬å¸åç§°åˆ†ç»„
            company_groups = {}
            company_field = 'å…¬å¸åç§°'
            
            for row in excel_data:
                company_name = row.get(company_field, '').strip()
                if not company_name:
                    company_name = 'æœªçŸ¥å…¬å¸'
                
                if company_name not in company_groups:
                    company_groups[company_name] = []
                company_groups[company_name].append(row)
            
            logger.info(f"ğŸ“Š æŒ‰å…¬å¸åç§°åˆ†ç»„ï¼Œå…± {len(company_groups)} ä¸ªå…¬å¸")
            
            # ä¸ºæ¯ä¸ªå…¬å¸ç”Ÿæˆæ–‡æ¡£
            output_dir = os.path.dirname(output_path)
            base_name = os.path.splitext(os.path.basename(output_path))[0]
            generated_files = []
            total_rows = 0
            
            for company_name, company_data in company_groups.items():
                # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
                safe_company_name = "".join(c for c in company_name if c.isalnum() or c in (' ', '-', '_')).strip()
                if not safe_company_name:
                    safe_company_name = "æœªçŸ¥å…¬å¸"
                
                # æ™ºèƒ½å¤„ç†æ‹¬å·ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«æ‹¬å·å¹¶ç›¸åº”å¤„ç†
                import re
                logger.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - åŸå§‹base_name: '{base_name}'")
                logger.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - å…¬å¸åç§°: '{safe_company_name}'")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡æ‹¬å·æˆ–è‹±æ–‡æ‹¬å·
                has_brackets = ('(' in base_name and ')' in base_name) or ('ï¼ˆ' in base_name and 'ï¼‰' in base_name)
                logger.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - æ˜¯å¦åŒ…å«æ‹¬å·: {has_brackets}")
                
                if has_brackets:
                    # å¦‚æœåŒ…å«æ‹¬å·ï¼Œæ›¿æ¢æ•´ä¸ªæ‹¬å·åŠå…¶å†…å®¹ï¼ˆæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡æ‹¬å·ï¼‰
                    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢ä¸­æ–‡æ‹¬å·æˆ–è‹±æ–‡æ‹¬å·åŠå…¶å†…å®¹
                    new_base_name = re.sub(r'[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]', f'({safe_company_name})', base_name)
                    logger.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - æ›¿æ¢åçš„base_name: '{new_base_name}'")
                    company_output_path = os.path.join(output_dir, f"{new_base_name}.docx")
                else:
                    # å¦‚æœä¸åŒ…å«æ‹¬å·ï¼Œæ·»åŠ æ‹¬å·å’Œå…¬å¸åç§°
                    logger.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - ä¸åŒ…å«æ‹¬å·ï¼Œç›´æ¥æ·»åŠ ")
                    company_output_path = os.path.join(output_dir, f"{base_name}({safe_company_name}).docx")
                
                logger.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - æœ€ç»ˆæ–‡ä»¶è·¯å¾„: '{company_output_path}'")
                
                # å¡«å……Wordè¡¨æ ¼
                result_path = self.fill_word_table(
                    word_template_path, 
                    company_data, 
                    company_output_path, 
                    0, 
                    column_mapping
                )
                
                generated_files.append(result_path)
                total_rows += len(company_data)
                logger.info(f"âœ… å·²ç”Ÿæˆ {company_name} çš„æ–‡æ¡£: {os.path.basename(result_path)} ({len(company_data)} è¡Œæ•°æ®)")
            
            return {
                'success': True,
                'error': None,
                'output_path': generated_files[0] if generated_files else None,  # è¿”å›ç¬¬ä¸€ä¸ªæ–‡ä»¶è·¯å¾„
                'generated_files': generated_files,
                'rows_filled': total_rows,
                'total_rows_detected': len(excel_data),
                'groups_count': len(company_groups)
            }
            
        except Exception as e:
            logger.error(f"æŒ‰å…¬å¸åˆ†ç»„å¤„ç†å‡ºé”™: {e}")
            return {
                'success': False,
                'error': str(e),
                'output_path': None,
                'rows_filled': 0,
                'total_rows_detected': len(excel_data)
            }
    
    def _process_by_group(self, excel_data: List[Dict[str, Any]], 
                        word_template_path: str, output_path: str,
                        column_mapping: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
        """
        æŒ‰ç¾¤åç§°åˆ†ç»„å¤„ç†ï¼ŒåŒä¸€ç¾¤çš„æ•°æ®ç”Ÿæˆä¸€ä¸ªæ–‡æ¡£
        """
        try:
            # æŒ‰ç¾¤åç§°åˆ†ç»„
            group_groups = {}
            group_field = 'ç¾¤åç§°'
            company_field = 'å…¬å¸åç§°'
            
            for row in excel_data:
                group_name = row.get(group_field, '').strip()
                if not group_name:
                    # å¦‚æœæ²¡æœ‰ç¾¤åç§°ï¼Œä½¿ç”¨å…¬å¸åç§°ä½œä¸ºç¾¤åç§°
                    group_name = row.get(company_field, '').strip()
                    if not group_name:
                        group_name = 'æœªçŸ¥ç¾¤ç»„'
                
                if group_name not in group_groups:
                    group_groups[group_name] = []
                group_groups[group_name].append(row)
            
            logger.info(f"ğŸ“Š æŒ‰ç¾¤åç§°åˆ†ç»„ï¼Œå…± {len(group_groups)} ä¸ªç¾¤ç»„")
            
            # ä¸ºæ¯ä¸ªç¾¤ç»„ç”Ÿæˆæ–‡æ¡£
            output_dir = os.path.dirname(output_path)
            base_name = os.path.splitext(os.path.basename(output_path))[0]
            generated_files = []
            total_rows = 0
            
            for group_name, group_data in group_groups.items():
                # è·å–ç¾¤ç»„ä¸­ç¬¬ä¸€ä¸ªå…¬å¸åç§°ç”¨äºæ–‡ä»¶å
                first_company = ""
                for row in group_data:
                    company_name = row.get(company_field, '').strip()
                    if company_name:
                        first_company = company_name
                        break
                
                if not first_company:
                    first_company = "æœªçŸ¥å…¬å¸"
                
                # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
                safe_group_name = "".join(c for c in group_name if c.isalnum() or c in (' ', '-', '_')).strip()
                safe_company_name = "".join(c for c in first_company if c.isalnum() or c in (' ', '-', '_')).strip()
                
                if not safe_group_name:
                    safe_group_name = "æœªçŸ¥ç¾¤ç»„"
                if not safe_company_name:
                    safe_company_name = "æœªçŸ¥å…¬å¸"
                
                # æ™ºèƒ½å¤„ç†æ‹¬å·ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«æ‹¬å·å¹¶ç›¸åº”å¤„ç†
                import re
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡æ‹¬å·æˆ–è‹±æ–‡æ‹¬å·
                if ('(' in base_name and ')' in base_name) or ('ï¼ˆ' in base_name and 'ï¼‰' in base_name):
                    # å¦‚æœåŒ…å«æ‹¬å·ï¼Œæ›¿æ¢æ•´ä¸ªæ‹¬å·åŠå…¶å†…å®¹ï¼ˆæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡æ‹¬å·ï¼‰
                    # ä½¿ç”¨ç¾¤ç»„ä¸­ç¬¬ä¸€ä¸ªå…¬å¸çš„åç§°ä½œä¸ºæ–‡ä»¶å
                    new_base_name = re.sub(r'[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]', f'({safe_company_name})', base_name)
                    group_output_path = os.path.join(output_dir, f"{new_base_name}.docx")
                else:
                    # å¦‚æœä¸åŒ…å«æ‹¬å·ï¼Œæ·»åŠ æ‹¬å·å’Œç¬¬ä¸€ä¸ªå…¬å¸åç§°
                    group_output_path = os.path.join(output_dir, f"{base_name}({safe_company_name}).docx")
                
                # å¡«å……Wordè¡¨æ ¼
                result_path = self.fill_word_table(
                    word_template_path, 
                    group_data, 
                    group_output_path, 
                    0, 
                    column_mapping
                )
                
                generated_files.append(result_path)
                total_rows += len(group_data)
                logger.info(f"âœ… å·²ç”Ÿæˆç¾¤ç»„ {group_name} çš„æ–‡æ¡£: {os.path.basename(result_path)} ({len(group_data)} è¡Œæ•°æ®)")
            
            return {
                'success': True,
                'error': None,
                'output_path': generated_files[0] if generated_files else None,  # è¿”å›ç¬¬ä¸€ä¸ªæ–‡ä»¶è·¯å¾„
                'generated_files': generated_files,
                'rows_filled': total_rows,
                'total_rows_detected': len(excel_data),
                'groups_count': len(group_groups)
            }
            
        except Exception as e:
            logger.error(f"æŒ‰ç¾¤ç»„åˆ†ç»„å¤„ç†å‡ºé”™: {e}")
            return {
                'success': False,
                'error': str(e),
                'output_path': None,
                'rows_filled': 0,
                'total_rows_detected': len(excel_data)
            }

def create_default_column_mapping() -> Dict[str, str]:
    """
    åˆ›å»ºé»˜è®¤çš„åˆ—æ˜ å°„å…³ç³»
    åŸºäºWordè¡¨æ ¼å­—æ®µä¸Excelæ•°æ®åˆ—çš„å¯¹åº”å…³ç³»
    Wordè¡¨æ ¼å­—æ®µ -> Excelåˆ—å
    """
    return {
        'å®¢æˆ·': 'å…¬å¸åç§°',           # å¯¹åº”Excelçš„"å…¬å¸åç§°"åˆ—
        'å›½å®¶': 'å›½å®¶',             # å¯¹åº”Excelçš„"å›½å®¶"åˆ—  
        'ç”³æŠ¥æ–¹å¼': 'ç”³æŠ¥æ–¹å¼',       # å¯¹åº”Excelçš„"ç”³æŠ¥æ–¹å¼"åˆ—
        'ç”³æŠ¥æ—¶æ®µ': 'ç”³æŠ¥æ—¶æ®µ',       # å¯¹åº”Excelçš„"ç”³æŠ¥æ—¶æ®µ"åˆ—
        'ä¸‹è½½æ•°æ®æ ¼å¼': 'ä¸‹è½½æ•°æ®æ ¼å¼',   # å¯¹åº”Excelçš„"ä¸‹è½½æ•°æ®æ ¼å¼"åˆ—
        'å¤‡æ³¨(å¦‚å·²ç»­è´¹ï¼Œè¯·å¿½ç•¥ï¼‰': 'å¤‡æ³¨'  # å¯¹åº”Excelçš„"å¤‡æ³¨"åˆ—
    }


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    processor = DocumentProcessor()
    
    # æµ‹è¯•è·¯å¾„
    excel_path = "/Volumes/oldman_space/work_space/vies-on-the-soft/25.08æœˆç”³æŠ¥æ˜ç»†æ±‡æ€»è¡¨.xlsx"
    word_path = "/Volumes/oldman_space/work_space/vies-on-the-soft/VATç”³æŠ¥æ˜ç»†è¡¨æ¨¡æ¿.docx"
    output_path = "/Volumes/oldman_space/work_space/vies-on-the-soft/VATç”³æŠ¥æ˜ç»†è¡¨_å·²å¡«å…….docx"
    
    try:
        # æµ‹è¯•Excelæ•°æ®æå–
        data = processor.extract_excel_data(excel_path)
        print(f"æå–åˆ° {len(data)} è¡Œæ•°æ®")
        
        if data:
            print("å‰3è¡Œæ•°æ®:")
            for i, row in enumerate(data[:3]):
                print(f"ç¬¬{i+1}è¡Œ: {row}")
        
        # æµ‹è¯•Wordæ–‡æ¡£åˆ†æ
        if os.path.exists(word_path):
            analysis = processor.analyze_word_document(word_path)
            print(f"Wordæ–‡æ¡£åˆ†æç»“æœ: {analysis}")
            
            # æµ‹è¯•å®Œæ•´å¤„ç†æµç¨‹
            column_mapping = create_default_column_mapping()
            result = processor.process_documents(
                excel_path, word_path, output_path, 
                sheet_name=None, column_mapping=column_mapping
            )
            print(f"å¤„ç†å®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶: {result}")
        else:
            print(f"Wordæ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {word_path}")
            
    except Exception as e:
        print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")